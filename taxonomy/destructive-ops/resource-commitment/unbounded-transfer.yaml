id: "destructive-ops/resource-commitment/unbounded-transfer"
version: "1.0.0"
kingdom: "Destructive Operations"
kingdom_id: 1
category: "Uncontrolled Resource Commitment"
category_id: "1.5"
name: "Unbounded Financial Transfer"
risk_level: "critical"

abstract: |
  An AI agent executes a financial transfer or resource commitment without
  enforcing value limits, risking catastrophic loss from parsing errors,
  misinterpreted instructions, or social engineering.

explanation: |
  Autonomous AI agents increasingly interact with financial APIs, crypto
  wallets, payment processors, and resource-provisioning services via MCP
  tool calls or direct API invocations. Without enforced value limits, a
  single parsing error or prompt injection can cause irreversible loss.

  Real-world example — the Lobstar Wilde incident (February 2026):
  An autonomous crypto trading bot attempted to send 4 SOL (~$4) to a
  user but instead transferred its entire token balance (~52 million
  tokens, valued at ~$250,000) due to a technical/parsing error. The
  blockchain transfer was irreversible and the funds were immediately
  sold by the recipient.

  Root causes include:
  - No maximum transaction value enforced at the tool call layer
  - No confirmation step for high-value actions
  - Agent social-engineered via a sarcastic reply on social media
  - Brittle error handling: a minor constraint cascaded into total
    state loss and the agent defaulted to sending everything

  This class of vulnerability applies to any agent-initiated action with
  real-world cost: token transfers, cloud resource provisioning, API
  calls with per-call charges, marketplace purchases, and subscription
  commitments.

recommendation: |
  - Enforce value limits on tool call arguments using MCP policy
    (AgentShield `value_limits` rules).
  - Set per-transaction maximums for financial operations.
  - Set per-session cumulative budgets where possible.
  - Require human-in-the-loop confirmation for transactions above a
    threshold.
  - Treat all external user input as untrusted — agents should not
    execute financial actions based on social media replies.
  - Implement fail-safe defaults: on error, abort the transaction
    rather than sending maximum/all.

examples:
  bad:
    - "send_tokens(to='random_user', amount=52439000)"
    - "transfer(wallet='attacker', amount=ALL_BALANCE)"
    - "provision_instances(count=1000, type='p4d.24xlarge')"
    - "purchase(item='widget', quantity=999999)"
  good:
    - "send_tokens(to='user', amount=4)  # within configured limit"
    - "transfer(wallet='known', amount=50)  # under max threshold"
    - "provision_instances(count=2, type='t3.micro')  # reasonable"

compliance:
  owasp-llm-2025: ["LLM06", "LLM05"]

references:
  mitre_attack: ["T1657"]
  cwe: ["CWE-770"]
  external:
    - title: "Lobstar Wilde incident: AI trading bot loses $250K"
      url: "https://crypto.news/ai-trading-bot-lobstar-wilde-transfer-memecoin-2026/"
    - title: "AI Agent Boom in 2025 Sparks Innovation and Risks"
      url: "https://mezha.net/eng/bukvy/ai-agent-boom-in-2025-sparks-innovation-and-risks/"
    - title: "OWASP LLM06: Excessive Agency"
      url: "https://genai.owasp.org/llmrisk/llm062025-excessive-agency/"

analyzers: ["mcp-value-limits", "mcp-policy"]
related_rules: ["block-large-transfer", "audit-medium-payment"]
